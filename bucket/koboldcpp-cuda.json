{
  "version": "1.30.3",
  "description": "A simple one-file way to run various GGML models like LLAMA, ALPACA, VICUNA",
  "homepage": "https://github.com/LostRuins/koboldcpp",
  "license": "AGPL-3.0",
  "notes": "Look Mobel *.bin weights at https://rentry.org/nur779",
  "architecture": {
    "64bit": {
      "url": "https://ghproxy.com/https://github.com/LostRuins/koboldcpp/releases/download/v1.30.3/koboldcpp_CUDA_only.exe",
      "hash": "C481327B183048D0DCBFBD5F86E2A0E1BE607266D140BBD946AEB13CED6E05AA"
    }
  },
  "bin": "koboldcpp_CUDA_only.exe",
  "shortcuts": [
    [
      "koboldcpp_CUDA_only.exe",
      "KoboldCpp"
    ]
  ]
}
